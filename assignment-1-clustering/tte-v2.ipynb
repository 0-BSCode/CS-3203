{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.duration.hazard_regression import PHReg\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, Any\n",
    "import tempfile\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CensorWeightCalculator Class Documentation\n",
    "## Overview\n",
    "\n",
    "The `CensorWeightCalculator` class is a tool for calculating stabilized inverse probability of censoring weights (IPCW) in survival analysis. These weights help adjust for censoring bias in longitudinal data, where subjects may drop out or be lost to follow-up before the event of interest occurs. By estimating the probability of censoring using logistic regression models, the class computes weights that can be used to produce unbiased survival estimates, such as in Kaplan-Meier estimators or Cox proportional hazards models.\n",
    "\n",
    "The class supports flexible modeling strategies, allowing users to fit period-specific models or pool models across all periods for the numerator and/or denominator of the weights. It includes error handling, regularization, and weight stabilization features to ensure robust performance across diverse datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## Class Definition\n",
    "\n",
    "```python\n",
    "class CensorWeightCalculator:\n",
    "    def __init__(self, model_fitter, censor_event, pool_models=\"none\"):\n",
    "        self.model_fitter = model_fitter\n",
    "        self.censor_event = censor_event\n",
    "        self.pool_models = pool_models  # \"none\", \"numerator\", \"denominator\", or \"both\"\n",
    "```\n",
    "\n",
    "### Initialization Parameters\n",
    "\n",
    "- **`model_fitter`**:\n",
    "  - **Type**: Model class (e.g., `statsmodels.api.Logit`)\n",
    "  - **Description**: The logistic regression model class used to fit censoring probability models. It must support the `.fit_regularized()` method for regularization and `.predict()` for probability estimation.\n",
    "- **`censor_event`**:\n",
    "  - **Type**: str\n",
    "  - **Description**: The name of the column in the dataset that indicates censoring status (1 if censored, 0 otherwise).\n",
    "- **`pool_models`**:\n",
    "  - **Type**: str, default=\"none\"\n",
    "  - **Description**: Specifies the pooling strategy for fitting models across time periods. Options are:\n",
    "    - `\"none\"`: Fit separate models for each period for both numerator and denominator.\n",
    "    - `\"numerator\"`: Fit a pooled model for the numerator across all periods, with period-specific denominator models.\n",
    "    - `\"denominator\"`: Fit a pooled model for the denominator across all periods, with period-specific numerator models.\n",
    "    - `\"both\"`: Fit pooled models for both numerator and denominator across all periods.\n",
    "\n",
    "### Attributes\n",
    "\n",
    "- `self.model_fitter`: Stores the provided model fitter class.\n",
    "- `self.censor_event`: Stores the censoring event column name.\n",
    "- `self.pool_models`: Stores the pooling strategy.\n",
    "\n",
    "---\n",
    "\n",
    "## Methods\n",
    "\n",
    "### `fit`\n",
    "\n",
    "```python\n",
    "def fit(self, data, numerator_vars, denominator_vars, id_col, period_col):\n",
    "    \"\"\"Calculate censoring weights.\"\"\"\n",
    "    # Implementation details provided in the description below\n",
    "```\n",
    "\n",
    "#### Description\n",
    "\n",
    "The `fit` method calculates stabilized IPCW for each subject at each time period in the dataset. It fits logistic regression models (either period-specific or pooled) to predict the probability of censoring, computes weights as the ratio of probabilities of not being censored, and applies stabilization techniques to ensure robustness.\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "- **`data`**:\n",
    "  - **Type**: pandas.DataFrame\n",
    "  - **Description**: The input dataset containing censoring information, covariates, and time period data.\n",
    "- **`numerator_vars`**:\n",
    "  - **Type**: list\n",
    "  - **Description**: List of column names in `data` used as predictors in the numerator model for censoring probability.\n",
    "- **`denominator_vars`**:\n",
    "  - **Type**: list\n",
    "  - **Description**: List of column names in `data` used as predictors in the denominator model for censoring probability. Typically includes more variables than `numerator_vars` for stabilization.\n",
    "- **`id_col`**:\n",
    "  - **Type**: str\n",
    "  - **Description**: The name of the column in `data` that uniquely identifies subjects.\n",
    "- **`period_col`**:\n",
    "  - **Type**: str\n",
    "  - **Description**: The name of the column in `data` that indicates the time period (e.g., follow-up time).\n",
    "\n",
    "#### Returns\n",
    "\n",
    "- **Type**: pandas.DataFrame\n",
    "- **Description**: A DataFrame containing the calculated weights with columns:\n",
    "  - `[id_col]`: Subject identifier.\n",
    "  - `[period_col]`: Time period.\n",
    "  - `'weight'`: The calculated censoring weight for each subject-period combination.\n",
    "\n",
    "#### Implementation Details\n",
    "\n",
    "1. **Data Preparation**:\n",
    "   - Creates a copy of the input `data` to avoid modifying the original dataset.\n",
    "2. **Pooled Model Fitting**:\n",
    "   - If `pool_models` is `\"numerator\"` or `\"both\"`, fits a pooled numerator model across all periods using `_fit_pooled_model`.\n",
    "   - If `pool_models` is `\"denominator\"` or `\"both\"`, fits a pooled denominator model across all periods using `_fit_pooled_model`.\n",
    "3. **Period-Specific Processing**:\n",
    "   - Iterates over each unique period in `period_col`:\n",
    "     - Extracts data for the current period.\n",
    "     - Defines a censoring indicator (`is_censored`) based on `censor_event` (1 if censored, 0 otherwise).\n",
    "     - Checks for variation in `is_censored`:\n",
    "       - If no variation (all 0s or all 1s), assigns weights of 1.0.\n",
    "       - Otherwise, proceeds with model fitting.\n",
    "4. **Model Fitting and Weight Calculation**:\n",
    "   - **Numerator Model**:\n",
    "     - If `pool_models` is not `\"numerator\"`, fits a period-specific model using `numerator_vars`.\n",
    "     - Otherwise, uses the pooled numerator model.\n",
    "   - **Denominator Model**:\n",
    "     - If `pool_models` is not `\"denominator\"`, fits a period-specific model using `denominator_vars`.\n",
    "     - Otherwise, uses the pooled denominator model.\n",
    "   - Uses `statsmodels`' `Logit` with regularization (`alpha=0.01`) to fit models.\n",
    "   - Predicts censoring probabilities (`num_probs` and `denom_probs`).\n",
    "   - Clips probabilities to [0.001, 0.999] to avoid division by zero or extreme weights.\n",
    "   - Calculates stabilized weights as `(1 - num_probs) / (1 - denom_probs)`.\n",
    "5. **Error Handling**:\n",
    "   - If model fitting fails (e.g., due to convergence issues or linear algebra errors), assigns weights of 1.0 and prints a warning.\n",
    "6. **Weight Stabilization**:\n",
    "   - Replaces NaN or infinite weights with 1.0.\n",
    "   - Trims weights exceeding the 99th percentile to reduce variability.\n",
    "7. **Output**:\n",
    "   - Concatenates period-specific results into a single DataFrame and returns it.\n",
    "\n",
    "---\n",
    "\n",
    "### `_fit_pooled_model` (Private Method)\n",
    "\n",
    "```python\n",
    "def _fit_pooled_model(self, data, vars_list):\n",
    "    \"\"\"Fit a pooled model across all periods.\"\"\"\n",
    "    # Implementation details provided in the description below\n",
    "```\n",
    "\n",
    "#### Description\n",
    "\n",
    "This private helper method fits a single logistic regression model across all periods to predict censoring probability. It is used for pooled models when `pool_models` is set to `\"numerator\"`, `\"denominator\"`, or `\"both\"`.\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "- **`data`**:\n",
    "  - **Type**: pandas.DataFrame\n",
    "  - **Description**: The input dataset containing all periods.\n",
    "- **`vars_list`**:\n",
    "  - **Type**: list\n",
    "  - **Description**: List of column names in `data` to use as predictors in the model.\n",
    "\n",
    "#### Returns\n",
    "\n",
    "- **Type**: Fitted model object or DummyModel\n",
    "- **Description**: Returns a fitted logistic regression model or a dummy model if fitting fails or thereâ€™s no variation in the outcome.\n",
    "\n",
    "#### Implementation Details\n",
    "\n",
    "1. **Censoring Indicator**:\n",
    "   - Creates `is_censored` based on `censor_event` (1 if censored, 0 otherwise).\n",
    "2. **Variation Check**:\n",
    "   - If `is_censored` has no variation (all 0s or all 1s), returns a `DummyModel` that predicts a constant probability equal to the mean of `is_censored`.\n",
    "3. **Model Fitting**:\n",
    "   - Adds a constant term to the predictors (`vars_list`) using `sm.add_constant`.\n",
    "   - Fits a logistic regression model using `model_fitter` with regularization (`alpha=0.01`).\n",
    "   - Returns the fitted model.\n",
    "4. **Error Handling**:\n",
    "   - If fitting fails (e.g., due to convergence issues or linear algebra errors), prints a warning and returns a `DummyModel` predicting the mean censoring probability.\n",
    "\n",
    "#### DummyModel Definition\n",
    "\n",
    "```python\n",
    "class DummyModel:\n",
    "    def predict(self, X):\n",
    "        return np.ones(len(X)) * constant_prob\n",
    "```\n",
    "\n",
    "- Predicts a constant probability for all inputs, used as a fallback when model fitting is not possible.\n",
    "\n",
    "---\n",
    "\n",
    "## Example Usage\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'id': [1, 1, 2, 2, 3, 3],\n",
    "    'period': [1, 2, 1, 2, 1, 2],\n",
    "    'censor': [0, 1, 0, 0, 1, 0],\n",
    "    'age': [25, 26, 30, 31, 40, 41],\n",
    "    'treatment': [0, 0, 1, 1, 0, 0]\n",
    "})\n",
    "\n",
    "# Initialize the calculator\n",
    "calculator = CensorWeightCalculator(\n",
    "    model_fitter=sm.Logit,\n",
    "    censor_event='censor',\n",
    "    pool_models='none'\n",
    ")\n",
    "\n",
    "# Calculate weights\n",
    "weights = calculator.fit(\n",
    "    data=data,\n",
    "    numerator_vars=['age'],\n",
    "    denominator_vars=['age', 'treatment'],\n",
    "    id_col='id',\n",
    "    period_col='period'\n",
    ")\n",
    "\n",
    "print(weights)\n",
    "```\n",
    "\n",
    "### Expected Output\n",
    "\n",
    "A DataFrame like:\n",
    "\n",
    "```\n",
    "   id  period    weight\n",
    "0   1       1  1.023456\n",
    "1   2       1  0.987654\n",
    "2   3       1  1.050000\n",
    "3   1       2  1.010000\n",
    "4   2       2  0.995000\n",
    "5   3       2  1.030000\n",
    "```\n",
    "\n",
    "(Values are illustrative; actual weights depend on the data and model fit.)\n",
    "\n",
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "- **Purpose**: The `CensorWeightCalculator` is ideal for survival analysis tasks where censoring bias needs to be addressed, such as in medical studies or longitudinal research.\n",
    "- **Stabilization**: Weights are stabilized using the ratio `(1 - num_probs) / (1 - denom_probs)`, where `numerator_vars` typically include fewer covariates than `denominator_vars` to reduce variability.\n",
    "- **Robustness**: Regularization (`alpha=0.01`) prevents overfitting, while clipping probabilities and trimming weights ensures numerical stability.\n",
    "- **Flexibility**: The `pool_models` parameter allows users to balance model complexity and stability based on data characteristics (e.g., sample size per period).\n",
    "- **Dependencies**: Requires `pandas`, `numpy`, and `statsmodels` libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CensorWeightCalculator:\n",
    "    def __init__(self, model_fitter, censor_event, pool_models=\"none\"):\n",
    "        self.model_fitter = model_fitter\n",
    "        self.censor_event = censor_event\n",
    "        self.pool_models = pool_models  # \"none\", \"numerator\", or \"denominator\"\n",
    "    \n",
    "    def fit(self, data, numerator_vars, denominator_vars, id_col, period_col):\n",
    "        \"\"\"Calculate censoring weights.\"\"\"\n",
    "        # Create a copy of the data\n",
    "        data_copy = data.copy()\n",
    "        \n",
    "        # Create pooled models if required\n",
    "        if self.pool_models in [\"numerator\", \"both\"]:\n",
    "            pooled_num_model = self._fit_pooled_model(data_copy, numerator_vars)\n",
    "        \n",
    "        if self.pool_models in [\"denominator\", \"both\"]:\n",
    "            pooled_denom_model = self._fit_pooled_model(data_copy, denominator_vars)\n",
    "        \n",
    "        # Get periods\n",
    "        periods = sorted(data_copy[period_col].unique())\n",
    "        \n",
    "        # Initialize DataFrame to store weights\n",
    "        weights_df = pd.DataFrame()\n",
    "        \n",
    "        for period in periods:\n",
    "            # Get data for current period\n",
    "            period_data = data_copy[data_copy[period_col] == period].copy()\n",
    "            \n",
    "            if len(period_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Define censoring indicator\n",
    "            period_data['is_censored'] = (period_data[self.censor_event] == 1).astype(int)\n",
    "            \n",
    "            # Check if we have variation in the outcome\n",
    "            if period_data['is_censored'].nunique() <= 1:\n",
    "                # No variation, assign weight of 1.0\n",
    "                period_data['weight'] = 1.0\n",
    "            else:\n",
    "                try:\n",
    "                    # Fit period-specific models or use pooled models\n",
    "                    if self.pool_models != \"numerator\":\n",
    "                        # Fit numerator model for this period with regularization\n",
    "                        X_num = sm.add_constant(period_data[numerator_vars])\n",
    "                        num_model = sm.Logit(period_data['is_censored'], X_num).fit_regularized(\n",
    "                            alpha=0.01, disp=0\n",
    "                        )\n",
    "                        num_probs = num_model.predict(X_num)\n",
    "                    else:\n",
    "                        # Use pooled numerator model\n",
    "                        X_num = sm.add_constant(period_data[numerator_vars])\n",
    "                        num_probs = pooled_num_model.predict(X_num)\n",
    "                    \n",
    "                    if self.pool_models != \"denominator\":\n",
    "                        # Fit denominator model for this period with regularization\n",
    "                        X_denom = sm.add_constant(period_data[denominator_vars])\n",
    "                        denom_model = sm.Logit(period_data['is_censored'], X_denom).fit_regularized(\n",
    "                            alpha=0.01, disp=0\n",
    "                        )\n",
    "                        denom_probs = denom_model.predict(X_denom)\n",
    "                    else:\n",
    "                        # Use pooled denominator model\n",
    "                        X_denom = sm.add_constant(period_data[denominator_vars])\n",
    "                        denom_probs = pooled_denom_model.predict(X_denom)\n",
    "                    \n",
    "                    # Ensure probabilities are not exactly 0 or 1\n",
    "                    num_probs = np.clip(num_probs, 0.001, 0.999)\n",
    "                    denom_probs = np.clip(denom_probs, 0.001, 0.999)\n",
    "                    \n",
    "                    # Calculate stabilized weights\n",
    "                    period_data['weight'] = (1 - num_probs) / (1 - denom_probs)\n",
    "                    \n",
    "                except (np.linalg.LinAlgError, ValueError) as e:\n",
    "                    print(f\"Warning: Model fitting failed for period {period}. Setting weights to 1.0. Error: {e}\")\n",
    "                    period_data['weight'] = 1.0\n",
    "                \n",
    "            # Handle any remaining NaNs or infinities\n",
    "            period_data['weight'] = period_data['weight'].fillna(1.0)\n",
    "            period_data.loc[np.isinf(period_data['weight']), 'weight'] = 1.0\n",
    "            \n",
    "            # Trim extreme weights\n",
    "            q99 = np.percentile(period_data['weight'], 99)\n",
    "            period_data.loc[period_data['weight'] > q99, 'weight'] = q99\n",
    "            \n",
    "            # Add to weights DataFrame\n",
    "            weights_df = pd.concat([weights_df, period_data[[id_col, period_col, 'weight']]])\n",
    "        \n",
    "        return weights_df\n",
    "\n",
    "    def _fit_pooled_model(self, data, vars_list):\n",
    "        \"\"\"Fit a pooled model across all periods.\"\"\"\n",
    "        # Create censoring indicator\n",
    "        data['is_censored'] = (data[self.censor_event] == 1).astype(int)\n",
    "        \n",
    "        # Check if we have variation in the outcome\n",
    "        if data['is_censored'].nunique() <= 1:\n",
    "            # Return a dummy model that always predicts the constant\n",
    "            constant_prob = data['is_censored'].mean()\n",
    "            class DummyModel:\n",
    "                def predict(self, X):\n",
    "                    return np.ones(len(X)) * constant_prob\n",
    "            return DummyModel()\n",
    "        \n",
    "        try:\n",
    "            # Fit model with regularization\n",
    "            X = sm.add_constant(data[vars_list])\n",
    "            model = sm.Logit(data['is_censored'], X).fit_regularized(alpha=0.01, disp=0)\n",
    "            return model\n",
    "        except (np.linalg.LinAlgError, ValueError) as e:\n",
    "            print(f\"Warning: Pooled model fitting failed. Creating dummy model. Error: {e}\")\n",
    "            # Return a dummy model\n",
    "            constant_prob = data['is_censored'].mean()\n",
    "            class DummyModel:\n",
    "                def predict(self, X):\n",
    "                    return np.ones(len(X)) * constant_prob\n",
    "            return DummyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OutcomeModel Class Documentation\n",
    "\n",
    "## Overview\n",
    "\n",
    "The `OutcomeModel` class is designed for survival analysis using a Cox proportional hazards model. It enables users to fit a model to longitudinal data and predict survival probabilities at specified time points for new data. The class supports adjustment for additional covariates beyond the treatment variable and incorporates observation weights in the model fitting process. It leverages the `statsmodels` library's `PHReg` implementation to perform the Cox regression and provides methods to check the model's fit status and generate predictions with confidence intervals.\n",
    "\n",
    "### Key Features\n",
    "- Fits a Cox proportional hazards model to survival data.\n",
    "- Predicts survival probabilities at user-specified time points with simplified confidence intervals.\n",
    "- Allows adjustment for additional covariates and weighted observations.\n",
    "\n",
    "---\n",
    "\n",
    "## Class Definition\n",
    "\n",
    "```python\n",
    "class OutcomeModel:\n",
    "    def __init__(self, adjustment_vars=None):\n",
    "        self.adjustment_vars = adjustment_vars\n",
    "        self.fitted_model = None\n",
    "        self.model_info = None\n",
    "```\n",
    "\n",
    "### Initialization Parameters\n",
    "- **`adjustment_vars`** (list of str, optional):  \n",
    "  Names of additional covariates to include in the model for adjustment (e.g., `['age', 'sex']`). If `None`, only the treatment variable is used in the model.  \n",
    "  Default: `None`.\n",
    "\n",
    "---\n",
    "\n",
    "## Methods\n",
    "\n",
    "### `__init__(self, adjustment_vars=None)`\n",
    "Initializes the `OutcomeModel` instance.\n",
    "\n",
    "#### Parameters\n",
    "- **`adjustment_vars`** (list of str, optional):  \n",
    "  List of covariate names to adjust for in the model. Stored in `self.adjustment_vars`.\n",
    "\n",
    "#### Attributes Initialized\n",
    "- `self.adjustment_vars`: Stores the adjustment variables.\n",
    "- `self.fitted_model`: Set to `None`, to be populated after fitting.\n",
    "- `self.model_info`: Set to `None`, to store model metadata after fitting.\n",
    "\n",
    "---\n",
    "\n",
    "### `fit(self, data, id_col, time_col, event_col, treatment_col, weight_col)`\n",
    "Fits a Cox proportional hazards model to the provided data.\n",
    "\n",
    "#### Parameters\n",
    "- **`data`** (pd.DataFrame):  \n",
    "  The dataset containing survival data, with columns for identifiers, time, event status, treatment, weights, and any adjustment variables.\n",
    "- **`id_col`** (str):  \n",
    "  Name of the column containing unique individual identifiers (e.g., `'id'`).\n",
    "- **`time_col`** (str):  \n",
    "  Name of the column with time-to-event or censoring time (e.g., `'follow_up_time'`).\n",
    "- **`event_col`** (str):  \n",
    "  Name of the column indicating event occurrence (1 for event, 0 for censored; e.g., `'event'`).\n",
    "- **`treatment_col`** (str):  \n",
    "  Name of the column indicating treatment assignment (e.g., `'trial_arm'`, where 0 might represent control and 1 treatment).\n",
    "- **`weight_col`** (str):  \n",
    "  Name of the column with observation weights (e.g., `'weight'`, for inverse probability weighting).\n",
    "\n",
    "#### Returns\n",
    "- `self`: The fitted `OutcomeModel` instance, enabling method chaining.\n",
    "\n",
    "#### Process\n",
    "- Creates a copy of the input `data` to avoid modifying the original DataFrame.\n",
    "- Constructs a formula dynamically: \n",
    "  - If `adjustment_vars` is provided, the formula becomes `\"{time_col} ~ {treatment_col} + {var1} + {var2} + ...\"`.\n",
    "  - If `adjustment_vars` is `None`, the formula is `\"{time_col} ~ {treatment_col}\"`.\n",
    "- Fits the Cox model using `PHReg.from_formula` from `statsmodels`, with:\n",
    "  - `formula`: Specifies the model structure.\n",
    "  - `data`: The copied dataset.\n",
    "  - `status`: Event indicators from `data[event_col]`.\n",
    "  - `weights`: Weights from `data[weight_col]`.\n",
    "- Stores the fitted model in `self.fitted_model`.\n",
    "- Stores additional model information in `self.model_info` as a dictionary with:\n",
    "  - `'model'`: The `PHReg` model instance.\n",
    "  - `'vcov'`: Variance-covariance matrix of the parameters.\n",
    "  - `'formula'`: The formula used for fitting.\n",
    "\n",
    "---\n",
    "\n",
    "### `is_fitted(self)`\n",
    "Checks whether the model has been fitted.\n",
    "\n",
    "#### Returns\n",
    "- `bool`: `True` if `self.fitted_model` is not `None`, `False` otherwise.\n",
    "\n",
    "---\n",
    "\n",
    "### `predict(self, data, times)`\n",
    "Predicts survival probabilities for the given data at specified time points.\n",
    "\n",
    "#### Parameters\n",
    "- **`data`** (pd.DataFrame):  \n",
    "  Dataset for prediction, containing the same columns as the training data (e.g., `treatment_col` and any `adjustment_vars`).\n",
    "- **`times`** (list or np.array):  \n",
    "  Time points at which to predict survival probabilities (e.g., `[0, 1, 2, 3, 4]`).\n",
    "\n",
    "#### Returns\n",
    "- `dict`: A dictionary containing:\n",
    "  - `'times'`: The input `times` (shape: `(n_times,)`).\n",
    "  - `'survival'`: 2D array of survival probabilities (shape: `(n_samples, n_times)`), where `n_samples` is the number of rows in `data`.\n",
    "  - `'lower'`: Lower bounds of the simplified 95% confidence intervals (shape: `(n_samples, n_times)`).\n",
    "  - `'upper'`: Upper bounds of the simplified 95% confidence intervals (shape: `(n_samples, n_times)`).\n",
    "\n",
    "#### Raises\n",
    "- `ValueError`: If the model is not fitted (`self.fitted_model` is `None`).\n",
    "\n",
    "#### Process\n",
    "- Copies the input `data` to avoid modification.\n",
    "- Estimates the baseline survival function at `times` using `_estimate_baseline_survival` (shape: `(n_times,)`).\n",
    "- Computes the linear predictor for `data` using `_calculate_linear_predictor` (shape: `(n_samples,)`).\n",
    "- Calculates survival probabilities as `survival = baseline_surv ** exp(lp)`, using broadcasting to produce a 2D array (shape: `(n_samples, n_times)`).\n",
    "- Computes simplified confidence intervals:\n",
    "  - `ci_width = 1.96 * 0.1 * survival` (assuming a 95% CI with a standard error proportional to survival).\n",
    "  - `lower = max(0, survival - ci_width)` to ensure non-negative probabilities.\n",
    "  - `upper = min(1, survival + ci_width)` to cap probabilities at 1.\n",
    "\n",
    "---\n",
    "\n",
    "### `_estimate_baseline_survival(self, times)`\n",
    "*Private method* to estimate the baseline survival function.\n",
    "\n",
    "#### Parameters\n",
    "- **`times`** (list or np.array):  \n",
    "  Time points for estimating baseline survival.\n",
    "\n",
    "#### Returns\n",
    "- `np.array`: Baseline survival probabilities at the specified `times` (shape: `(n_times,)`).\n",
    "\n",
    "#### Notes\n",
    "- This is a simplified implementation using an exponential model with a fixed hazard rate (`lambda_hat = 0.1`).\n",
    "- Formula: `S_0(t) = exp(-lambda_hat * t)`.\n",
    "- In a proper implementation, this should use the baseline hazard estimated from the fitted model (e.g., `self.fitted_model.baseline_cumulative_hazard_`), but the current version uses a placeholder for simplicity.\n",
    "\n",
    "---\n",
    "\n",
    "### `_calculate_linear_predictor(self, data)`\n",
    "*Private method* to compute the linear predictor for the input data.\n",
    "\n",
    "#### Parameters\n",
    "- **`data`** (pd.DataFrame):  \n",
    "  Dataset for which to compute the linear predictor, containing columns matching the modelâ€™s exogenous variables.\n",
    "\n",
    "#### Returns\n",
    "- `np.array`: Linear predictor values for each row in `data` (shape: `(n_samples,)`).\n",
    "\n",
    "#### Process\n",
    "- Retrieves the exogenous variable names from `self.fitted_model.model.exog_names` (e.g., `['Intercept', 'trial_arm', 'x2']`).\n",
    "- Constructs a design matrix `X`:\n",
    "  - For `'Intercept'`, sets the column to 1.\n",
    "  - For other variables, copies the corresponding column from `data`.\n",
    "- Computes the linear predictor as `lp = X @ self.fitted_model.params`, where `self.fitted_model.params` are the estimated coefficients.\n",
    "\n",
    "---\n",
    "\n",
    "## Limitations\n",
    "- **Baseline Survival**: The `_estimate_baseline_survival` method uses a simplified exponential model with a constant hazard rate (`lambda_hat = 0.1`). This does not reflect the actual baseline hazard from the data, which should be estimated from the fitted model for accuracy.\n",
    "- **Confidence Intervals**: The confidence intervals in `predict` are simplified (`ci_width = 1.96 * 0.1 * survival`), assuming a standard error proportional to the survival probability. In practice, confidence intervals should account for the variance in the baseline hazard and parameter estimates (e.g., using `self.model_info['vcov']`).\n",
    "- **Data Assumptions**: The `predict` method assumes `data` includes all columns specified in `treatment_col` and `adjustment_vars`. Missing columns will raise errors.\n",
    "- **Proportional Hazards Assumption**: The Cox model assumes that hazard ratios are constant over time, which may not hold for all datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## Example Usage\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'id': range(32),\n",
    "    'follow_up_time': np.random.exponential(5, 32),\n",
    "    'event': np.random.binomial(1, 0.7, 32),\n",
    "    'trial_arm': np.random.binomial(1, 0.5, 32),\n",
    "    'x2': np.random.normal(0, 1, 32),\n",
    "    'weight': np.ones(32)\n",
    "})\n",
    "\n",
    "# Initialize the model with adjustment variables\n",
    "model = OutcomeModel(adjustment_vars=['x2'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    data=data,\n",
    "    id_col='id',\n",
    "    time_col='follow_up_time',\n",
    "    event_col='event',\n",
    "    treatment_col='trial_arm',\n",
    "    weight_col='weight'\n",
    ")\n",
    "\n",
    "# Predict survival probabilities at times 0 to 10\n",
    "pred_data = data.copy()\n",
    "times = np.arange(11)\n",
    "predictions = model.predict(pred_data, times)\n",
    "\n",
    "# Plot average survival difference (treatment vs. control)\n",
    "treatment_mask = pred_data['trial_arm'] == 1\n",
    "surv_diff = (predictions['survival'][treatment_mask].mean(axis=0) - \n",
    "             predictions['survival'][~treatment_mask].mean(axis=0))\n",
    "plt.plot(times, surv_diff, label='Survival Difference', color='blue')\n",
    "plt.fill_between(\n",
    "    times,\n",
    "    predictions['lower'][treatment_mask].mean(axis=0) - predictions['upper'][~treatment_mask].mean(axis=0),\n",
    "    predictions['upper'][treatment_mask].mean(axis=0) - predictions['lower'][~treatment_mask].mean(axis=0),\n",
    "    color='red',\n",
    "    alpha=0.2,\n",
    "    label='95% CI'\n",
    ")\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.xlabel('Follow up')\n",
    "plt.ylabel('Survival Difference')\n",
    "plt.title('Treatment Effect on Survival')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutcomeModel:\n",
    "    def __init__(self, adjustment_vars=None):\n",
    "        self.adjustment_vars = adjustment_vars\n",
    "        self.fitted_model = None\n",
    "        self.model_info = None\n",
    "    \n",
    "    def fit(self, data, id_col, time_col, event_col, treatment_col, weight_col):\n",
    "        \"\"\"Fit a proportional hazards model.\"\"\"\n",
    "        model_data = data.copy()\n",
    "        \n",
    "        # Prepare formula\n",
    "        if self.adjustment_vars:\n",
    "            formula = f\"{time_col} ~ {treatment_col} + \" + \" + \".join(self.adjustment_vars)\n",
    "        else:\n",
    "            formula = f\"{time_col} ~ {treatment_col}\"\n",
    "        \n",
    "        # Fit Cox PH model\n",
    "        model = PHReg.from_formula(\n",
    "            formula,\n",
    "            data=model_data,\n",
    "            status=model_data[event_col],\n",
    "            weights=model_data[weight_col]\n",
    "        )\n",
    "        \n",
    "        result = model.fit()\n",
    "        \n",
    "        # Store fitted model\n",
    "        self.fitted_model = result\n",
    "        \n",
    "        # Store model info\n",
    "        self.model_info = {\n",
    "            'model': model,\n",
    "            'vcov': result.cov_params(),\n",
    "            'formula': formula\n",
    "        }\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def is_fitted(self):\n",
    "        \"\"\"Check if model is fitted.\"\"\"\n",
    "        return self.fitted_model is not None\n",
    "    \n",
    "    def predict(self, data, times):\n",
    "        \"\"\"Predict survival probabilities.\"\"\"\n",
    "        if not self.is_fitted():\n",
    "            raise ValueError(\"Model not fitted yet.\")\n",
    "        \n",
    "        # Prepare prediction data\n",
    "        pred_data = data.copy()\n",
    "        \n",
    "        # Get baseline survival (shape: (11,))\n",
    "        baseline_surv = self._estimate_baseline_survival(times)\n",
    "        \n",
    "        # Get linear predictor (shape: (32,))\n",
    "        lp = self._calculate_linear_predictor(pred_data)\n",
    "        \n",
    "        # Calculate survival probabilities (shape: (32, 11))\n",
    "        survival = np.power(baseline_surv, np.exp(lp)[:, np.newaxis])\n",
    "        \n",
    "        # Calculate confidence intervals (simplified)\n",
    "        ci_width = 1.96 * 0.1 * survival  # Simplified CI\n",
    "        \n",
    "        return {\n",
    "            'times': times,\n",
    "            'survival': survival,\n",
    "            'lower': np.maximum(0, survival - ci_width),\n",
    "            'upper': np.minimum(1, survival + ci_width)\n",
    "        }\n",
    "    \n",
    "    def _estimate_baseline_survival(self, times):\n",
    "        \"\"\"Estimate baseline survival function.\"\"\"\n",
    "        # This is a simplified implementation\n",
    "        # A proper implementation would estimate the baseline hazard from the data\n",
    "        \n",
    "        # For simplicity, we'll use an exponential model\n",
    "        # In real implementation, this would be based on the fitted model's baseline hazard\n",
    "        lambda_hat = 0.1  # Placeholder hazard rate\n",
    "        return np.exp(-lambda_hat * np.array(times))\n",
    "    \n",
    "    def _calculate_linear_predictor(self, data):\n",
    "        exog_names = self.fitted_model.model.exog_names  # ['Intercept', 'trial_arm', 'x2']\n",
    "        X = pd.DataFrame(index=data.index)\n",
    "        for name in exog_names:\n",
    "            if name == 'Intercept':\n",
    "                X[name] = 1\n",
    "            else:\n",
    "                X[name] = data[name]\n",
    "        return X.values @ self.fitted_model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TrialSequence` Class Documentation\n",
    "\n",
    "The `TrialSequence` class is a Python implementation designed to emulate clinical trials for causal inference, specifically for per-protocol (PP) and intention-to-treat (ITT) analyses. It mimics the functionality of the R package `TrialEmulation` by facilitating trial emulation, weight calculation, marginal structural model (MSM) fitting, and survival prediction. The class uses a `dataclass` structure to manage trial-related data and provides methods for data preparation, weight computation, trial expansion, model fitting, and prediction.\n",
    "\n",
    "---\n",
    "\n",
    "## Class Overview\n",
    "\n",
    "The `TrialSequence` class is built to handle longitudinal data with repeated measures, allowing users to emulate hypothetical trials, adjust for confounding using inverse probability weights, and estimate treatment effects using survival analysis.\n",
    "\n",
    "### Dependencies\n",
    "- `pandas` for data manipulation\n",
    "- `numpy` for numerical operations\n",
    "- `statsmodels` for survival analysis (Cox proportional hazards model)\n",
    "- `random` for random sampling\n",
    "- Python `dataclasses` and `typing` for structured data management\n",
    "\n",
    "---\n",
    "\n",
    "## Attributes\n",
    "\n",
    "The `TrialSequence` class uses a `dataclass` to define its attributes, providing a clean and structured way to store trial-related data.\n",
    "\n",
    "| Attribute            | Type                  | Default | Description                                                                 |\n",
    "|----------------------|-----------------------|---------|-----------------------------------------------------------------------------|\n",
    "| `estimand`           | `str`                 | -       | The type of estimand to analyze: `\"PP\"` (per-protocol) or `\"ITT\"` (intention-to-treat). Required upon initialization. |\n",
    "| `data`               | `Optional[pd.DataFrame]` | `None`  | The input dataset containing longitudinal trial data.               |\n",
    "| `id_col`             | `Optional[str]`       | `None`  | Name of the column in `data` identifying unique individuals.        |\n",
    "| `period_col`         | `Optional[str]`       | `None`  | Name of the column in `data` indicating time periods.               |\n",
    "| `treatment_col`      | `Optional[str]`       | `None`  | Name of the column in `data` indicating treatment assignment (binary: 0 or 1). |\n",
    "| `outcome_col`        | `Optional[str]`       | `None`  | Name of the column in `data` indicating the outcome (event indicator: 0 or 1). |\n",
    "| `eligible_col`       | `Optional[str]`       | `None`  | Name of the column in `data` indicating eligibility for trial emulation (0 or 1). |\n",
    "| `switch_weights`     | `Optional[pd.DataFrame]` | `None`  | DataFrame containing switch weights to adjust for treatment switching (PP analysis). |\n",
    "| `censor_weights`     | `Optional[pd.DataFrame]` | `None`  | DataFrame containing censoring weights to adjust for informative censoring. |\n",
    "| `combined_weights`   | `Optional[pd.DataFrame]` | `None`  | DataFrame containing combined weights (product of switch and censor weights). |\n",
    "| `outcome_model`      | `Optional[Any]`       | `None`  | The fitted outcome model object (e.g., an instance of `OutcomeModel`) for survival analysis. |\n",
    "| `expansion`          | `Optional[pd.DataFrame]` | `None`  | Expanded trial data created by `expand_trials`, used for fitting the MSM. |\n",
    "| `expansion_options`  | `Optional[Dict]`      | `None`  | Dictionary containing options for trial expansion, such as chunk size and output handler. |\n",
    "\n",
    "---\n",
    "\n",
    "## Methods\n",
    "\n",
    "### `__init__(estimand: str)`\n",
    "Initializes a new `TrialSequence` instance.\n",
    "\n",
    "#### Parameters\n",
    "- `estimand` (`str`): The type of estimand to analyze. Must be `\"PP\"` (per-protocol) or `\"ITT\"` (intention-to-treat).\n",
    "\n",
    "#### Example\n",
    "```python\n",
    "trial = TrialSequence(estimand=\"ITT\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### `set_data(data: pd.DataFrame, id: str, period: str, treatment: str, outcome: str, eligible: str) -> TrialSequence`\n",
    "Sets the input data and column names for the trial sequence.\n",
    "\n",
    "#### Parameters\n",
    "- `data` (`pd.DataFrame`): The input dataset containing longitudinal trial data.\n",
    "- `id` (`str`): Name of the column in `data` identifying unique individuals.\n",
    "- `period` (`str`): Name of the column in `data` indicating time periods.\n",
    "- `treatment` (`str`): Name of the column in `data` indicating treatment assignment (binary: 0 or 1).\n",
    "- `outcome` (`str`): Name of the column in `data` indicating the outcome (event indicator: 0 or 1).\n",
    "- `eligible` (`str`): Name of the column in `data` indicating eligibility for trial emulation (0 or 1).\n",
    "\n",
    "#### Returns\n",
    "- `self`: Returns the `TrialSequence` instance for method chaining.\n",
    "\n",
    "#### Example\n",
    "```python\n",
    "data = pd.DataFrame({\n",
    "    'id': [1, 1, 2, 2],\n",
    "    'period': [0, 1, 0, 1],\n",
    "    'treatment': [0, 1, 0, 0],\n",
    "    'outcome': [0, 1, 0, 0],\n",
    "    'eligible': [1, 1, 1, 1]\n",
    "})\n",
    "trial.set_data(data, id=\"id\", period=\"period\", treatment=\"treatment\", outcome=\"outcome\", eligible=\"eligible\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### `set_switch_weight_model(numerator: str, denominator: str, model_fitter: Any) -> TrialSequence`\n",
    "Sets up and calculates switch weights to adjust for treatment switching (used in PP analysis).\n",
    "\n",
    "#### Parameters\n",
    "- `numerator` (`str`): R-style formula string for the numerator model (e.g., `\"~ age\"`).\n",
    "- `denominator` (`str`): R-style formula string for the denominator model (e.g., `\"~ age + x1\"`).\n",
    "- `model_fitter` (`Any`): A model fitter object (e.g., `StatsGlmLogit`) to fit logistic regression models for switch weights.\n",
    "\n",
    "#### Returns\n",
    "- `self`: Returns the `TrialSequence` instance for method chaining.\n",
    "\n",
    "#### Notes\n",
    "- Switch weights are calculated using stabilized inverse probability weights to adjust for treatment switching over time.\n",
    "- The `model_fitter` should have a `fit` method that accepts the data, treatment column, numerator and denominator variables, and ID and period columns.\n",
    "\n",
    "#### Example\n",
    "```python\n",
    "trial.set_switch_weight_model(\n",
    "    numerator=\"~ age\",\n",
    "    denominator=\"~ age + x1\",\n",
    "    model_fitter=StatsGlmLogit(save_path=\"switch_models\")\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### `set_censor_weight_model(censor_event: str, numerator: str, denominator: str, pool_models: str, model_fitter: Any) -> TrialSequence`\n",
    "Sets up and calculates censoring weights to adjust for informative censoring.\n",
    "\n",
    "#### Parameters\n",
    "- `censor_event` (`str`): Name of the censoring indicator column in `data` (0 or 1).\n",
    "- `numerator` (`str`): R-style formula string for the numerator model (e.g., `\"~ x2\"`).\n",
    "- `denominator` (`str`): R-style formula string for the denominator model (e.g., `\"~ x2 + x1\"`).\n",
    "- `pool_models` (`str`): Strategy for pooling models across periods: `\"none\"`, `\"numerator\"`, or `\"denominator\"`.\n",
    "- `model_fitter` (`Any`): A model fitter object (e.g., `StatsGlmLogit`) to fit logistic regression models for censoring weights.\n",
    "\n",
    "#### Returns\n",
    "- `self`: Returns the `TrialSequence` instance for method chaining.\n",
    "\n",
    "#### Notes\n",
    "- Censoring weights are calculated using stabilized inverse probability of censoring weights.\n",
    "- Requires a `CensorWeightCalculator` object to handle the weight computation.\n",
    "\n",
    "#### Example\n",
    "```python\n",
    "trial.set_censor_weight_model(\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"~ x2\",\n",
    "    denominator=\"~ x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    model_fitter=StatsGlmLogit(save_path=\"censor_models\")\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### `calculate_weights() -> TrialSequence`\n",
    "Combines switch and censor weights into a single set of weights for analysis.\n",
    "\n",
    "#### Returns\n",
    "- `self`: Returns the `TrialSequence` instance for method chaining.\n",
    "\n",
    "#### Raises\n",
    "- `ValueError`: If neither `switch_weights` nor `censor_weights` have been calculated.\n",
    "\n",
    "#### Notes\n",
    "- Creates a DataFrame of all possible individual-period combinations.\n",
    "- Merges switch and censor weights, filling missing weights with 1.0.\n",
    "- Computes combined weights as the product of switch and censor weights.\n",
    "\n",
    "#### Example\n",
    "```python\n",
    "trial.calculate_weights()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### `set_outcome_model(adjustment_terms: Optional[str] = None) -> TrialSequence`\n",
    "Sets up the outcome model for survival analysis.\n",
    "\n",
    "#### Parameters\n",
    "- `adjustment_terms` (`Optional[str]`): R-style formula string for adjustment terms (e.g., `\"~ x2\"`). If `None`, no adjustment terms are used.\n",
    "\n",
    "#### Returns\n",
    "- `self`: Returns the `TrialSequence` instance for method chaining.\n",
    "\n",
    "#### Notes\n",
    "- Creates an `OutcomeModel` instance, optionally with adjustment variables.\n",
    "\n",
    "#### Example\n",
    "```python\n",
    "trial.set_outcome_model(adjustment_terms=\"~ x2\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### `set_expansion_options(output: Optional[Callable] = None, chunk_size: int = 500) -> TrialSequence`\n",
    "Sets options for trial data expansion.\n",
    "\n",
    "#### Parameters\n",
    "- `output` (`Optional[Callable]`): An output handler function to process expanded data (default: `None`).\n",
    "- `chunk_size` (`int`): Number of individuals to process per chunk during expansion (default: 500).\n",
    "\n",
    "#### Returns\n",
    "- `self`: Returns the `TrialSequence` instance for method chaining.\n",
    "\n",
    "#### Example\n",
    "```python\n",
    "trial.set_expansion_options(output=save_to_datatable(), chunk_size=500)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### `expand_trials() -> TrialSequence`\n",
    "Expands the trial data for analysis, creating a dataset of emulated trials.\n",
    "\n",
    "#### Returns\n",
    "- `self`: Returns the `TrialSequence` instance for method chaining.\n",
    "\n",
    "#### Raises\n",
    "- `ValueError`: If `expansion_options` are not set (call `set_expansion_options` first).\n",
    "\n",
    "#### Notes\n",
    "- Processes individuals in chunks to manage memory usage.\n",
    "- Calls `_expand_individuals` to generate trial records for each chunk.\n",
    "\n",
    "#### Example\n",
    "```python\n",
    "trial.expand_trials()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### `_expand_individuals(data: pd.DataFrame) -> pd.DataFrame`\n",
    "Creates expanded trial data for a subset of individuals.\n",
    "\n",
    "#### Parameters\n",
    "- `data` (`pd.DataFrame`): Subset of the input data for the current chunk of individuals.\n",
    "\n",
    "#### Returns\n",
    "- `pd.DataFrame`: Expanded trial data for the given individuals.\n",
    "\n",
    "#### Notes\n",
    "- For each individual, identifies eligible periods and creates trial records.\n",
    "- Computes survival time and event status for each trial.\n",
    "- Includes baseline covariates and weights from `combined_weights`.\n",
    "\n",
    "---\n",
    "\n",
    "### `load_expanded_data(seed: Optional[int] = None, p_control: float = 0.5) -> TrialSequence`\n",
    "Loads the expanded trial data and applies sampling weights.\n",
    "\n",
    "#### Parameters\n",
    "- `seed` (`Optional[int]`): Random seed for reproducibility (default: `None`).\n",
    "- `p_control` (`float`): Probability of assignment to the control arm (default: 0.5).\n",
    "\n",
    "#### Returns\n",
    "- `self`: Returns the `TrialSequence` instance for method chaining.\n",
    "\n",
    "#### Raises\n",
    "- `ValueError`: If `expansion` is `None` (call `expand_trials` first).\n",
    "\n",
    "#### Notes\n",
    "- Adds sampling weights to balance treatment assignment probabilities.\n",
    "\n",
    "#### Example\n",
    "```python\n",
    "trial.load_expanded_data(seed=1234, p_control=0.5)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### `fit_msm(weight_cols: List[str], modify_weights: Optional[Callable] = None) -> TrialSequence`\n",
    "Fits a marginal structural model (MSM) using a Cox proportional hazards model.\n",
    "\n",
    "#### Parameters\n",
    "- `weight_cols` (`List[str]`): List of column names for additional weights (e.g., `[\"sample_weight\"]`).\n",
    "- `modify_weights` (`Optional[Callable]`): Function to modify combined weights (e.g., winsorization at the 99th percentile).\n",
    "\n",
    "#### Returns\n",
    "- `self`: Returns the `TrialSequence` instance for method chaining.\n",
    "\n",
    "#### Raises\n",
    "- `ValueError`: If `expansion` is `None` (call `expand_trials` first).\n",
    "\n",
    "#### Notes\n",
    "- Fits the model using `survival_time` and `event` columns from the expanded data.\n",
    "- Combines weights from `combined_weights` and additional `weight_cols`.\n",
    "\n",
    "#### Example\n",
    "```python\n",
    "trial.fit_msm(\n",
    "    weight_cols=[\"sample_weight\"],\n",
    "    modify_weights=lambda w: np.minimum(w, np.quantile(w, 0.99))\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### `predict(newdata: pd.DataFrame, predict_times: List[int], type: str = \"survival\") -> Dict`\n",
    "Predicts survival outcomes based on the fitted MSM.\n",
    "\n",
    "#### Parameters\n",
    "- `newdata` (`pd.DataFrame`): Data for prediction, with the same structure as the training data.\n",
    "- `predict_times` (`List[int]`): List of time points at which to predict survival probabilities (e.g., `[0, 1, ..., 10]`).\n",
    "- `type` (`str`): Type of prediction (default: `\"survival\"`).\n",
    "\n",
    "#### Returns\n",
    "- `Dict`: A dictionary containing:\n",
    "  - `arm_0`: Survival predictions for the control arm (treatment = 0).\n",
    "  - `arm_1`: Survival predictions for the treatment arm (treatment = 1).\n",
    "  - `difference`: DataFrame with columns `followup_time`, `survival_diff`, `2.5%`, and `97.5%`, representing the difference in survival probabilities and confidence intervals.\n",
    "\n",
    "#### Raises\n",
    "- `ValueError`: If the outcome model is not fitted (call `fit_msm` first).\n",
    "\n",
    "#### Example\n",
    "```python\n",
    "prediction_data = trial.expansion[trial.expansion['trial_period'] == 1]\n",
    "preds = trial.predict(\n",
    "    newdata=prediction_data,\n",
    "    predict_times=list(range(11)),\n",
    "    type=\"survival\"\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### `_formula_to_vars(formula: Union[str, Any]) -> List[str]`\n",
    "Converts an R-style formula string to a list of variable names.\n",
    "\n",
    "#### Parameters\n",
    "- `formula` (`Union[str, Any]`): R-style formula string (e.g., `\"~ age + x1\"`).\n",
    "\n",
    "#### Returns\n",
    "- `List[str]`: List of variable names extracted from the formula (e.g., `[\"age\", \"x1\"]`).\n",
    "\n",
    "#### Notes\n",
    "- Handles formulas by removing the `~` and splitting on `+`.\n",
    "\n",
    "---\n",
    "\n",
    "## Example Usage\n",
    "Below is a complete example of using the `TrialSequence` class to emulate trials, fit an MSM, and predict survival differences:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.duration.hazard_regression import PHReg\n",
    "\n",
    "# Create a sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'id': [1, 1, 2, 2],\n",
    "    'period': [0, 1, 0, 1],\n",
    "    'treatment': [0, 1, 0, 0],\n",
    "    'outcome': [0, 1, 0, 0],\n",
    "    'eligible': [1, 1, 1, 1],\n",
    "    'censored': [0, 0, 0, 1],\n",
    "    'age': [30, 30, 40, 40],\n",
    "    'x1': [0.5, 0.6, 0.3, 0.4]\n",
    "})\n",
    "\n",
    "# Initialize TrialSequence for ITT analysis\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "\n",
    "# Set data\n",
    "trial_itt.set_data(\n",
    "    data=data,\n",
    "    id=\"id\",\n",
    "    period=\"period\",\n",
    "    treatment=\"treatment\",\n",
    "    outcome=\"outcome\",\n",
    "    eligible=\"eligible\"\n",
    ")\n",
    "\n",
    "# Set censoring weights\n",
    "trial_itt.set_censor_weight_model(\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"~ age\",\n",
    "    denominator=\"~ age + x1\",\n",
    "    pool_models=\"none\",\n",
    "    model_fitter=StatsGlmLogit()\n",
    ")\n",
    "\n",
    "# Calculate weights\n",
    "trial_itt.calculate_weights()\n",
    "\n",
    "# Set outcome model with adjustment\n",
    "trial_itt.set_outcome_model(adjustment_terms=\"~ age\")\n",
    "\n",
    "# Set expansion options and expand trials\n",
    "trial_itt.set_expansion_options(chunk_size=500)\n",
    "trial_itt.expand_trials()\n",
    "\n",
    "# Load expanded data\n",
    "trial_itt.load_expanded_data(seed=1234, p_control=0.5)\n",
    "\n",
    "# Fit MSM\n",
    "trial_itt.fit_msm(weight_cols=[\"sample_weight\"])\n",
    "\n",
    "# Predict survival differences\n",
    "prediction_data = trial_itt.expansion[trial_itt.expansion['trial_period'] == 1].copy()\n",
    "prediction_data['Intercept'] = 1  # Ensure intercept for prediction\n",
    "preds = trial_itt.predict(\n",
    "    newdata=prediction_data,\n",
    "    predict_times=list(range(11)),\n",
    "    type=\"survival\"\n",
    ")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(preds['difference']['followup_time'], preds['difference']['survival_diff'], label=\"Survival Difference\")\n",
    "plt.plot(preds['difference']['followup_time'], preds['difference']['2.5%'], 'r--', label=\"95% CI\")\n",
    "plt.plot(preds['difference']['followup_time'], preds['difference']['97.5%'], 'r--')\n",
    "plt.axhline(0, color='blue', linestyle='--')\n",
    "plt.xlabel(\"Follow up\")\n",
    "plt.ylabel(\"Survival difference\")\n",
    "plt.title(\"Treatment Effect on Survival\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Notes\n",
    "- **Weight Calculations**: The class supports inverse probability weights for treatment switching (PP) and censoring (PP and ITT), crucial for unbiased causal inference.\n",
    "- **Trial Expansion**: The `expand_trials` method emulates randomized trials by creating a dataset where each eligible period for an individual starts a new trial.\n",
    "- **Survival Analysis**: Uses `statsmodels`â€™ `PHReg` for fitting a Cox proportional hazards model, allowing for time-to-event analysis.\n",
    "- **Flexibility**: The class is designed to handle large datasets by processing individuals in chunks during trial expansion.\n",
    "\n",
    "---\n",
    "\n",
    "## Limitations\n",
    "- The current implementation assumes a binary treatment variable (`0` for control, `1` for treatment).\n",
    "- Confidence intervals in `predict` are simplified and may not be statistically rigorous (consider using bootstrap methods for better intervals).\n",
    "- The baseline survival estimation in `OutcomeModel` may need enhancement to align with Râ€™s event-driven approach (e.g., using Kaplan-Meier or Breslow estimator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataclass to mimic the trial_sequence object in R\n",
    "@dataclass\n",
    "class TrialSequence:\n",
    "    estimand: str  # \"PP\" or \"ITT\"\n",
    "    data: Optional[pd.DataFrame] = None\n",
    "    id_col: Optional[str] = None\n",
    "    period_col: Optional[str] = None\n",
    "    treatment_col: Optional[str] = None\n",
    "    outcome_col: Optional[str] = None\n",
    "    eligible_col: Optional[str] = None\n",
    "    switch_weights: Optional[pd.DataFrame] = None\n",
    "    censor_weights: Optional[pd.DataFrame] = None\n",
    "    combined_weights: Optional[pd.DataFrame] = None\n",
    "    outcome_model: Optional[Any] = None\n",
    "    expansion: Optional[pd.DataFrame] = None\n",
    "    expansion_options: Optional[Dict] = None\n",
    "    \n",
    "    def set_data(self, data, id, period, treatment, outcome, eligible):\n",
    "        \"\"\"Set the data and column names for the trial sequence.\"\"\"\n",
    "        self.data = data\n",
    "        self.id_col = id\n",
    "        self.period_col = period\n",
    "        self.treatment_col = treatment\n",
    "        self.outcome_col = outcome\n",
    "        self.eligible_col = eligible\n",
    "        return self\n",
    "    \n",
    "    def set_switch_weight_model(self, numerator, denominator, model_fitter):\n",
    "        \"\"\"Set the switch weight model specifications.\"\"\"\n",
    "        # Convert R formula strings to lists of variable names\n",
    "        num_vars = self._formula_to_vars(numerator)\n",
    "        denom_vars = self._formula_to_vars(denominator)\n",
    "        \n",
    "        # Calculate switch weights\n",
    "        self.switch_weights = model_fitter.fit(\n",
    "            self.data, \n",
    "            self.treatment_col,\n",
    "            num_vars,\n",
    "            denom_vars,\n",
    "            self.id_col,\n",
    "            self.period_col\n",
    "        )\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def set_censor_weight_model(self, censor_event, numerator, denominator, pool_models, model_fitter):\n",
    "        \"\"\"Set the censoring weight model specifications.\"\"\"\n",
    "        # Convert R formula strings to lists of variable names\n",
    "        num_vars = self._formula_to_vars(numerator)\n",
    "        denom_vars = self._formula_to_vars(denominator)\n",
    "        \n",
    "        # Calculate censoring weights\n",
    "        censor_calculator = CensorWeightCalculator(\n",
    "            model_fitter=model_fitter,\n",
    "            censor_event=censor_event,\n",
    "            pool_models=pool_models\n",
    "        )\n",
    "        \n",
    "        self.censor_weights = censor_calculator.fit(\n",
    "            self.data,\n",
    "            num_vars,\n",
    "            denom_vars,\n",
    "            self.id_col,\n",
    "            self.period_col\n",
    "        )\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def calculate_weights(self):\n",
    "        \"\"\"Combine switch and censor weights.\"\"\"\n",
    "        if self.switch_weights is None and self.censor_weights is None:\n",
    "            raise ValueError(\"No weights have been calculated yet.\")\n",
    "        \n",
    "        # Create a base DataFrame with all patient-periods\n",
    "        all_periods = pd.DataFrame({\n",
    "            self.id_col: self.data[self.id_col].unique()\n",
    "        }).merge(\n",
    "            pd.DataFrame({self.period_col: self.data[self.period_col].unique()}),\n",
    "            how='cross'\n",
    "        )\n",
    "        \n",
    "        # Merge with switch weights if available\n",
    "        if self.switch_weights is not None:\n",
    "            all_periods = pd.merge(\n",
    "                all_periods,\n",
    "                self.switch_weights[[self.id_col, self.period_col, 'weight']],\n",
    "                on=[self.id_col, self.period_col],\n",
    "                how='left'\n",
    "            )\n",
    "            all_periods.rename(columns={'weight': 'switch_weight'}, inplace=True)\n",
    "            all_periods['switch_weight'].fillna(1.0, inplace=True)\n",
    "        else:\n",
    "            all_periods['switch_weight'] = 1.0\n",
    "        \n",
    "        # Merge with censor weights if available\n",
    "        if self.censor_weights is not None:\n",
    "            all_periods = pd.merge(\n",
    "                all_periods,\n",
    "                self.censor_weights[[self.id_col, self.period_col, 'weight']],\n",
    "                on=[self.id_col, self.period_col],\n",
    "                how='left'\n",
    "            )\n",
    "            all_periods.rename(columns={'weight': 'censor_weight'}, inplace=True)\n",
    "            all_periods['censor_weight'].fillna(1.0, inplace=True)\n",
    "        else:\n",
    "            all_periods['censor_weight'] = 1.0\n",
    "        \n",
    "        # Calculate combined weight\n",
    "        all_periods['weight'] = all_periods['switch_weight'] * all_periods['censor_weight']\n",
    "        \n",
    "        # Store combined weights\n",
    "        self.combined_weights = all_periods\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def set_outcome_model(self, adjustment_terms=None):\n",
    "        \"\"\"Set up the outcome model for survival analysis.\"\"\"\n",
    "        if adjustment_terms is None:\n",
    "            self.outcome_model = OutcomeModel()\n",
    "        else:\n",
    "            adj_vars = self._formula_to_vars(adjustment_terms)\n",
    "            self.outcome_model = OutcomeModel(adjustment_vars=adj_vars)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def set_expansion_options(self, output=None, chunk_size=500):\n",
    "        \"\"\"Set options for trial expansion.\"\"\"\n",
    "        self.expansion_options = {\n",
    "            'output_handler': output,\n",
    "            'chunk_size': chunk_size\n",
    "        }\n",
    "        return self\n",
    "    \n",
    "    def expand_trials(self):\n",
    "        \"\"\"Expand the trial data for analysis.\"\"\"\n",
    "        if self.expansion_options is None:\n",
    "            raise ValueError(\"Expansion options not set. Call set_expansion_options first.\")\n",
    "        \n",
    "        # Get unique individuals\n",
    "        individuals = self.data[self.id_col].unique()\n",
    "        \n",
    "        # Process in chunks\n",
    "        chunk_size = self.expansion_options['chunk_size']\n",
    "        results = []\n",
    "        \n",
    "        for i in range(0, len(individuals), chunk_size):\n",
    "            chunk_ids = individuals[i:i+chunk_size]\n",
    "            \n",
    "            # Filter data for current chunk\n",
    "            chunk_data = self.data[self.data[self.id_col].isin(chunk_ids)].copy()\n",
    "            \n",
    "            # Create expanded data\n",
    "            expanded = self._expand_individuals(chunk_data)\n",
    "            results.append(expanded)\n",
    "        \n",
    "        # Combine results\n",
    "        self.expansion = pd.concat(results, ignore_index=True)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _expand_individuals(self, data):\n",
    "        \"\"\"Create expanded data for a set of individuals with survival times.\"\"\"\n",
    "        expanded_data = []\n",
    "        \n",
    "        for id_val in data[self.id_col].unique():\n",
    "            # Get individual's data, sorted by period\n",
    "            indiv_data = data[data[self.id_col] == id_val].sort_values(by=self.period_col)\n",
    "            \n",
    "            # Find event time: first period where outcome == 1 or censored == 1\n",
    "            event_rows = indiv_data[(indiv_data[self.outcome_col] == 1) | (indiv_data['censored'] == 1)]\n",
    "            if not event_rows.empty:\n",
    "                event_time = event_rows.iloc[0][self.period_col]\n",
    "                event_status = event_rows.iloc[0][self.outcome_col]\n",
    "            else:\n",
    "                # No event or censoring; assume censored at last period\n",
    "                event_time = indiv_data[self.period_col].max()\n",
    "                event_status = 0\n",
    "            \n",
    "            # Eligible start periods are before or at event_time\n",
    "            eligible_data = indiv_data[(indiv_data[self.eligible_col] == 1) & \n",
    "                                    (indiv_data[self.period_col] <= event_time)]\n",
    "            \n",
    "            for _, row in eligible_data.iterrows():\n",
    "                start_period = row[self.period_col]\n",
    "                trial_arm = row[self.treatment_col]\n",
    "                survival_time = event_time - start_period\n",
    "                event = event_status\n",
    "                \n",
    "                # Create trial record\n",
    "                record = {\n",
    "                    self.id_col: id_val,\n",
    "                    'trial_period': start_period,\n",
    "                    'trial_arm': trial_arm,\n",
    "                    'survival_time': survival_time,\n",
    "                    'event': event,\n",
    "                }\n",
    "                \n",
    "                # Include baseline covariates from start period\n",
    "                for col in self.data.columns:\n",
    "                    if col not in [self.id_col, self.period_col, self.treatment_col, \n",
    "                                self.outcome_col, 'censored', self.eligible_col]:\n",
    "                        record[col] = row[col]\n",
    "                \n",
    "                # Include weight for this trial from combined_weights\n",
    "                if self.combined_weights is not None:\n",
    "                    weight_row = self.combined_weights[\n",
    "                        (self.combined_weights[self.id_col] == id_val) & \n",
    "                        (self.combined_weights[self.period_col] == start_period)\n",
    "                    ]\n",
    "                    record['weight'] = weight_row['weight'].values[0] if not weight_row.empty else 1.0\n",
    "                else:\n",
    "                    record['weight'] = 1.0\n",
    "                \n",
    "                expanded_data.append(record)\n",
    "        \n",
    "        return pd.DataFrame(expanded_data)\n",
    "    \n",
    "    def load_expanded_data(self, seed=None, p_control=0.5):\n",
    "        \"\"\"Load expanded data and apply sampling weights.\"\"\"\n",
    "        if self.expansion is None:\n",
    "            raise ValueError(\"No expanded data available. Call expand_trials first.\")\n",
    "        \n",
    "        # Set random seed if provided\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        # Sample from expanded data\n",
    "        expanded_data = self.expansion.copy()\n",
    "        \n",
    "        # Calculate sampling weights based on treatment assignment\n",
    "        expanded_data['sample_weight'] = np.where(\n",
    "            expanded_data['trial_arm'] == 0,  # Assuming 0 is control\n",
    "            1.0 / p_control,\n",
    "            1.0 / (1.0 - p_control)\n",
    "        )\n",
    "        \n",
    "        # Store back to expansion\n",
    "        self.expansion = expanded_data\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def fit_msm(self, weight_cols, modify_weights=None):\n",
    "        \"\"\"\n",
    "        Fit a marginal structural model using a Cox proportional hazards model.\n",
    "\n",
    "        Parameters:\n",
    "        - weight_cols: List of column names for additional weights (e.g., censoring weights).\n",
    "        - modify_weights: Optional function to modify combined weights (e.g., winsorization).\n",
    "        \"\"\"\n",
    "        # Check if expanded data exists\n",
    "        if self.expansion is None:\n",
    "            raise ValueError(\"No expanded data available. Call expand_trials first.\")\n",
    "        \n",
    "        # Prepare a copy of the expanded data\n",
    "        model_data = self.expansion.copy()\n",
    "        \n",
    "        # Combine weights: start with trial weights, then multiply by additional weights\n",
    "        model_data['combined_weight'] = model_data['weight']\n",
    "        for col in weight_cols:\n",
    "            if col in model_data.columns:\n",
    "                model_data['combined_weight'] *= model_data[col]\n",
    "        \n",
    "        # Apply weight modification if provided\n",
    "        if modify_weights is not None:\n",
    "            model_data['combined_weight'] = modify_weights(model_data['combined_weight'])\n",
    "        \n",
    "        # Ensure the outcome model is set\n",
    "        if self.outcome_model is None:\n",
    "            self.set_outcome_model()\n",
    "        \n",
    "        # Define the time variable (endog), event status (status), and covariates (exog)\n",
    "        endog = model_data['survival_time']  # Time-to-event variable\n",
    "        status = model_data['event']         # Event indicator (1 if event occurred, 0 if censored)\n",
    "        exog = sm.add_constant(model_data[['trial_arm']])  # Covariates: intercept + treatment\n",
    "        \n",
    "        # Include adjustment variables if specified\n",
    "        if self.outcome_model.adjustment_vars:\n",
    "            exog = pd.concat([exog, model_data[self.outcome_model.adjustment_vars]], axis=1)\n",
    "        \n",
    "        # Fit the Cox PH model\n",
    "        model = PHReg(endog, exog, status=status, weights=model_data['combined_weight'])\n",
    "        self.outcome_model.fitted_model = model.fit()\n",
    "        \n",
    "        # Store model information\n",
    "        self.outcome_model.model_info = {\n",
    "            'model': model,\n",
    "            'vcov': self.outcome_model.fitted_model.cov_params(),\n",
    "            'exog_names': exog.columns.tolist()\n",
    "        }\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, newdata, predict_times, type=\"survival\"):\n",
    "        \"\"\"Predict outcomes based on the fitted model.\"\"\"\n",
    "        if self.outcome_model is None or not self.outcome_model.is_fitted():\n",
    "            raise ValueError(\"Outcome model not fitted. Call fit_msm first.\")\n",
    "        \n",
    "        # Prepare prediction data\n",
    "        pred_data = newdata.copy()\n",
    "        \n",
    "        # Make predictions for each treatment arm\n",
    "        results = {}\n",
    "        for arm in [0, 1]:  # Binary treatment (0=control, 1=treatment)\n",
    "            pred_data['trial_arm'] = arm\n",
    "            surv_curves = self.outcome_model.predict(pred_data, predict_times)\n",
    "            # Compute mean over individuals (axis=0) for each time point\n",
    "            mean_survival = np.mean(surv_curves['survival'], axis=0)\n",
    "            mean_lower = np.mean(surv_curves['lower'], axis=0)\n",
    "            mean_upper = np.mean(surv_curves['upper'], axis=0)\n",
    "            results[f'arm_{arm}'] = {\n",
    "                'times': surv_curves['times'],\n",
    "                'survival': mean_survival,\n",
    "                'lower': mean_lower,\n",
    "                'upper': mean_upper\n",
    "            }\n",
    "        \n",
    "        # Calculate difference (treatment effect)\n",
    "        diff_data = pd.DataFrame({\n",
    "            'followup_time': predict_times,\n",
    "            'survival_diff': results['arm_1']['survival'] - results['arm_0']['survival'],\n",
    "            '2.5%': results['arm_1']['lower'] - results['arm_0']['upper'],  # Simplified CI\n",
    "            '97.5%': results['arm_1']['upper'] - results['arm_0']['lower']  # Simplified CI\n",
    "        })\n",
    "        \n",
    "        return {\n",
    "            'arm_0': results['arm_0'],\n",
    "            'arm_1': results['arm_1'],\n",
    "            'difference': diff_data\n",
    "        }\n",
    "    \n",
    "    def _formula_to_vars(self, formula):\n",
    "        \"\"\"Convert an R-style formula to a list of variable names.\"\"\"\n",
    "        if isinstance(formula, str):\n",
    "            # Remove ~ and split by +\n",
    "            parts = formula.replace(\"~\", \"\").split(\"+\")\n",
    "            return [part.strip() for part in parts]\n",
    "        else:\n",
    "            # For our example, we'll handle the simpler case where the formula is a string like \"~ age + x1 + x3\"\n",
    "            # For the case where formula is passed as a tilde object in R, we just extract the string after the tilde\n",
    "            formula_str = formula.replace(\"~\", \"\")\n",
    "            parts = formula_str.split(\"+\")\n",
    "            return [part.strip() for part in parts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `StatsGlmLogit` Class Documentation\n",
    "\n",
    "## Overview\n",
    "\n",
    "The `StatsGlmLogit` class is a Python utility designed to fit logistic regression models and calculate stabilized inverse probability weights (IPW) for longitudinal data analysis. These weights are commonly used in causal inference to adjust for confounding due to treatment switching over time. The class is particularly suited for survival analysis contexts, such as estimating treatment effects on survival outcomes, and supports optional saving of fitted models for later use or inspection.\n",
    "\n",
    "### Key Features\n",
    "- Fits logistic regression models for numerator (simpler) and denominator (full) components to calculate stabilized weights.\n",
    "- Handles longitudinal data with multiple time periods and treatment switching.\n",
    "- Optionally saves fitted models to a specified directory.\n",
    "- Returns a DataFrame with stabilized weights for each individual and period.\n",
    "\n",
    "---\n",
    "\n",
    "## Class Definition\n",
    "\n",
    "```python\n",
    "class StatsGlmLogit:\n",
    "    def __init__(self, save_path=None):\n",
    "        self.save_path = save_path\n",
    "        if save_path and not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "```\n",
    "\n",
    "### Initialization Parameters\n",
    "- **`save_path`** (str, optional):  \n",
    "  Path to a directory where fitted logistic regression models will be saved. If provided, the directory is created if it does not exist.  \n",
    "  **Default**: `None` (models are not saved).\n",
    "\n",
    "---\n",
    "\n",
    "## Methods\n",
    "\n",
    "### `__init__(self, save_path=None)`\n",
    "Initializes the `StatsGlmLogit` instance.\n",
    "\n",
    "#### Parameters\n",
    "- **`save_path`** (str, optional):  \n",
    "  Directory path for saving fitted models. If specified and the directory does not exist, it is created using `os.makedirs`.\n",
    "\n",
    "#### Attributes Initialized\n",
    "- **`self.save_path`**: Stores the provided `save_path` or `None` if not specified.\n",
    "\n",
    "---\n",
    "\n",
    "### `fit(self, data, treatment_col, numerator_vars, denominator_vars, id_col, period_col)`\n",
    "Fits logistic regression models to calculate stabilized weights for each time period based on treatment switching.\n",
    "\n",
    "#### Parameters\n",
    "- **`data`** (pd.DataFrame):  \n",
    "  Input longitudinal dataset containing columns for treatment, covariates, individual identifiers, and time periods.\n",
    "- **`treatment_col`** (str):  \n",
    "  Name of the column indicating treatment assignment (e.g., `'treatment'`), typically binary (0 or 1).\n",
    "- **`numerator_vars`** (list of str):  \n",
    "  List of covariate names for the numerator logistic regression model (e.g., `['age', 'baseline_severity']`). This model is simpler, often including time-invariant or baseline covariates.\n",
    "- **`denominator_vars`** (list of str):  \n",
    "  List of covariate names for the denominator logistic regression model (e.g., `['age', 'baseline_severity', 'time_varying_covariate']`). This model is more comprehensive, including covariates influencing treatment switching.\n",
    "- **`id_col`** (str):  \n",
    "  Name of the column with unique individual identifiers (e.g., `'id'`).\n",
    "- **`period_col`** (str):  \n",
    "  Name of the column indicating time periods (e.g., `'period'`), with integer values representing discrete time points.\n",
    "\n",
    "#### Returns\n",
    "- **`pd.DataFrame`**: A DataFrame containing stabilized weights with the following columns:\n",
    "  - `[id_col]`: Individual identifier.\n",
    "  - `[period_col]`: Time period.\n",
    "  - `'weight'`: Stabilized weight for each individual-period combination.\n",
    "\n",
    "#### Process\n",
    "1. **Extract Unique Periods**:  \n",
    "   Retrieves and sorts unique time periods from `data[period_col]`.\n",
    "2. **Initialize Weights DataFrame**:  \n",
    "   Creates an empty DataFrame to store weights across all periods.\n",
    "3. **Iterate Over Periods**:  \n",
    "   Loops through periods starting from the second one (since switching requires a prior period):\n",
    "   - **Filter Current Period Data**: Extracts data for the current period; skips if empty.\n",
    "   - **Identify Previous Period**: Determines the previous period from the sorted list.\n",
    "   - **Merge with Previous Data**: Combines current period data with previous periodâ€™s treatment data using `id_col`.\n",
    "   - **Detect Treatment Switching**: Creates a `'switched'` column (1 if treatment differs from the previous period, 0 otherwise).\n",
    "   - **Fit Numerator Model**: Fits a logistic regression model using `numerator_vars` to predict switching probability, suppressing output (`disp=0`).\n",
    "   - **Save Numerator Model**: If `save_path` is specified, saves the model as a pickle file (e.g., `num_model_period_1.pkl`).\n",
    "   - **Fit Denominator Model**: Fits a logistic regression model using `denominator_vars` to predict switching probability, suppressing output.\n",
    "   - **Save Denominator Model**: If `save_path` is specified, saves the model as a pickle file (e.g., `denom_model_period_1.pkl`).\n",
    "   - **Calculate Probabilities**: Computes predicted probabilities of switching from both models.\n",
    "   - **Compute Stabilized Weights**: Calculates weights as the ratio `num_probs / denom_probs`, replacing NaN values (e.g., from division by zero) with 1.0.\n",
    "   - **Append Weights**: Adds the current periodâ€™s weights to the weights DataFrame.\n",
    "4. **Return Weights**: Concatenates and returns the weights DataFrame for all periods.\n",
    "\n",
    "#### Dependencies\n",
    "- **`pandas`**: For data manipulation (`pd.DataFrame`, `pd.merge`, `pd.concat`).\n",
    "- **`statsmodels.api`**: For logistic regression (`sm.Logit`, `sm.add_constant`).\n",
    "- **`os`**: For directory handling (`os.path.exists`, `os.makedirs`).\n",
    "- **`pickle`**: For saving models (`pickle.dump`).\n",
    "\n",
    "---\n",
    "\n",
    "## Example Usage\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Sample longitudinal data\n",
    "data = pd.DataFrame({\n",
    "    'id': [1, 1, 2, 2, 3, 3],\n",
    "    'period': [0, 1, 0, 1, 0, 1],\n",
    "    'treatment': [0, 1, 0, 0, 1, 1],\n",
    "    'age': [25, 25, 30, 30, 35, 35],\n",
    "    'baseline_severity': [0.5, 0.5, 0.6, 0.6, 0.7, 0.7],\n",
    "    'time_varying_covariate': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "})\n",
    "\n",
    "# Initialize StatsGlmLogit with a save path\n",
    "model_fitter = StatsGlmLogit(save_path='fitted_models')\n",
    "\n",
    "# Fit models and calculate weights\n",
    "weights = model_fitter.fit(\n",
    "    data=data,\n",
    "    treatment_col='treatment',\n",
    "    numerator_vars=['age', 'baseline_severity'],\n",
    "    denominator_vars=['age', 'baseline_severity', 'time_varying_covariate'],\n",
    "    id_col='id',\n",
    "    period_col='period'\n",
    ")\n",
    "\n",
    "print(weights)\n",
    "```\n",
    "\n",
    "### Expected Output\n",
    "A DataFrame such as:\n",
    "\n",
    "```\n",
    "   id  period    weight\n",
    "0   1       1  1.023456\n",
    "1   2       1  0.987654\n",
    "2   3       1  1.050000\n",
    "```\n",
    "\n",
    "*Note*: Actual weight values depend on the data and model fit; the above are illustrative.\n",
    "\n",
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "- **Purpose**: The class calculates stabilized weights to adjust for confounding in longitudinal studies with time-varying treatments, often for causal inference in survival analysis.\n",
    "- **Stabilized Weights**: Computed as the ratio of probabilities from a simpler numerator model and a more comprehensive denominator model, these weights balance treatment switching probabilities across individuals.\n",
    "- **Model Persistence**: If `save_path` is provided, fitted models are saved as `.pkl` files, enabling inspection or reuse.\n",
    "- **Data Requirements**: Input must be a pandas DataFrame with columns for identifiers, periods, treatment, and covariates.\n",
    "\n",
    "---\n",
    "\n",
    "## Limitations\n",
    "\n",
    "- **First Period Exclusion**: No weights are calculated for the first period, as there is no prior treatment to compare for switching.\n",
    "- **Binary Treatment**: Assumes treatment is binary (0 or 1); non-binary treatments require modification.\n",
    "- **Model Convergence**: Logistic regression may fail to converge with insufficient variation or collinearity, potentially yielding weights of 1.0.\n",
    "- **Weight Stability**: Extreme weights may occur; NaN values are set to 1.0, but users should monitor for outliers.\n",
    "\n",
    "---\n",
    "\n",
    "## Relevance to Survival Analysis\n",
    "\n",
    "The `StatsGlmLogit` class is often used in survival analysis to estimate treatment effects over time, as depicted in the provided image attachments (e.g., \"Treatment Effect on Survival\" graphs). The stabilized weights adjust for confounding due to treatment switching, enabling more accurate estimation of survival differences between treated and untreated groups. These weights can be applied in models like Cox proportional hazards to produce plots showing survival differences over follow-up periods, as seen in the described graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatsGlmLogit:\n",
    "    def __init__(self, save_path=None):\n",
    "        self.save_path = save_path\n",
    "        if save_path and not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "    \n",
    "    def fit(self, data, treatment_col, numerator_vars, denominator_vars, id_col, period_col):\n",
    "        \"\"\"Fit logistic regression models and calculate stabilized weights.\"\"\"\n",
    "        # Get periods where treatment can switch\n",
    "        periods = sorted(data[period_col].unique())\n",
    "        \n",
    "        # Initialize DataFrame to store weights\n",
    "        weights_df = pd.DataFrame()\n",
    "        \n",
    "        for period in periods[1:]:  # Skip the first period as there's no prior treatment to switch from\n",
    "            # Get data for current period\n",
    "            period_data = data[data[period_col] == period].copy()\n",
    "            \n",
    "            if len(period_data) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Get previous period for each individual\n",
    "            prev_period = periods[periods.index(period) - 1]\n",
    "            prev_data = data[data[period_col] == prev_period].copy()\n",
    "            \n",
    "            # Merge current with previous period data\n",
    "            merged_data = pd.merge(\n",
    "                period_data,\n",
    "                prev_data[[id_col, treatment_col]],\n",
    "                on=id_col,\n",
    "                suffixes=('', '_prev')\n",
    "            )\n",
    "            \n",
    "            # Identify individuals who switched treatment\n",
    "            merged_data['switched'] = (merged_data[treatment_col] != merged_data[f\"{treatment_col}_prev\"]).astype(int)\n",
    "            \n",
    "            # Fit numerator model (simpler model)\n",
    "            X_num = sm.add_constant(merged_data[numerator_vars])\n",
    "            num_model = sm.Logit(merged_data['switched'], X_num).fit(disp=0)\n",
    "            \n",
    "            # Save model if requested\n",
    "            if self.save_path:\n",
    "                with open(os.path.join(self.save_path, f\"num_model_period_{period}.pkl\"), 'wb') as f:\n",
    "                    pickle.dump(num_model, f)\n",
    "            \n",
    "            # Fit denominator model (full model)\n",
    "            X_denom = sm.add_constant(merged_data[denominator_vars])\n",
    "            denom_model = sm.Logit(merged_data['switched'], X_denom).fit(disp=0)\n",
    "            \n",
    "            # Save model if requested\n",
    "            if self.save_path:\n",
    "                with open(os.path.join(self.save_path, f\"denom_model_period_{period}.pkl\"), 'wb') as f:\n",
    "                    pickle.dump(denom_model, f)\n",
    "            \n",
    "            # Calculate predicted probabilities\n",
    "            num_probs = num_model.predict(X_num)\n",
    "            denom_probs = denom_model.predict(X_denom)\n",
    "            \n",
    "            # Calculate stabilized weights\n",
    "            merged_data['weight'] = num_probs / denom_probs\n",
    "            merged_data['weight'] = merged_data['weight'].fillna(1.0)  # Handle division by zero\n",
    "            \n",
    "            # Add to weights DataFrame\n",
    "            weights_df = pd.concat([weights_df, merged_data[[id_col, period_col, 'weight']]])\n",
    "        \n",
    "        return weights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial_sequence(estimand):\n",
    "    \"\"\"Create a new trial sequence object.\"\"\"\n",
    "    return TrialSequence(estimand=estimand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_glm_logit(save_path=None):\n",
    "    \"\"\"Create a logistic regression model fitter.\"\"\"\n",
    "    return StatsGlmLogit(save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_datatable():\n",
    "    \"\"\"Handler for saving expanded data to a data table.\"\"\"\n",
    "    # This is a placeholder for the actual implementation\n",
    "    def handler(data):\n",
    "        return data\n",
    "    return handler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcome_data(trial):\n",
    "    \"\"\"Extract outcome data from a trial sequence.\"\"\"\n",
    "    if trial.expansion is not None:\n",
    "        return trial.expansion\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_weight_models(trial):\n",
    "    \"\"\"Display information about weight models.\"\"\"\n",
    "    print(\"Weight Models Summary:\")\n",
    "    if hasattr(trial, 'switch_weights') and trial.switch_weights is not None:\n",
    "        print(f\"  Switch Weights: {len(trial.switch_weights)} rows\")\n",
    "    \n",
    "    if hasattr(trial, 'censor_weights') and trial.censor_weights is not None:\n",
    "        print(f\"  Censor Weights: {len(trial.censor_weights)} rows\")\n",
    "    \n",
    "    if hasattr(trial, 'combined_weights') and trial.combined_weights is not None:\n",
    "        print(f\"  Combined Weights: {len(trial.combined_weights)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrialSequence(estimand='PP', data=     id  period  treatment  x1        x2  x3        x4  age     age_s  \\\n",
      "0     1       0          1   1  1.146148   0  0.734203   36  0.083333   \n",
      "1     1       1          1   1  0.002200   0  0.734203   37  0.166667   \n",
      "2     1       2          1   0 -0.481762   0  0.734203   38  0.250000   \n",
      "3     1       3          1   0  0.007872   0  0.734203   39  0.333333   \n",
      "4     1       4          1   1  0.216054   0  0.734203   40  0.416667   \n",
      "..   ..     ...        ...  ..       ...  ..       ...  ...       ...   \n",
      "720  99       3          0   0 -0.747906   1  0.575268   68  2.750000   \n",
      "721  99       4          0   0 -0.790056   1  0.575268   69  2.833333   \n",
      "722  99       5          1   1  0.387429   1  0.575268   70  2.916667   \n",
      "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000   \n",
      "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333   \n",
      "\n",
      "     outcome  censored  eligible  \n",
      "0          0         0         1  \n",
      "1          0         0         0  \n",
      "2          0         0         0  \n",
      "3          0         0         0  \n",
      "4          0         0         0  \n",
      "..       ...       ...       ...  \n",
      "720        0         0         0  \n",
      "721        0         0         0  \n",
      "722        0         0         0  \n",
      "723        0         0         0  \n",
      "724        1         0         0  \n",
      "\n",
      "[725 rows x 12 columns], id_col='id', period_col='period', treatment_col='treatment', outcome_col='outcome', eligible_col='eligible', switch_weights=    id  period    weight\n",
      "0    1       1  0.761800\n",
      "1    2       1  0.771315\n",
      "2    3       1  0.941859\n",
      "3    4       1  0.966432\n",
      "4    5       1  0.996027\n",
      "..  ..     ...       ...\n",
      "17  76      19  1.254239\n",
      "18  83      19  0.849307\n",
      "19  85      19  1.026541\n",
      "20  95      19  1.125288\n",
      "21  96      19  1.045674\n",
      "\n",
      "[636 rows x 3 columns], censor_weights=None, combined_weights=None, outcome_model=None, expansion=None, expansion_options=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryan Sanchez\\AppData\\Local\\Temp\\ipykernel_3748\\3626396832.py:91: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_periods['switch_weight'].fillna(1.0, inplace=True)\n",
      "C:\\Users\\Bryan Sanchez\\AppData\\Local\\Temp\\ipykernel_3748\\3626396832.py:104: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_periods['censor_weight'].fillna(1.0, inplace=True)\n",
      "C:\\Users\\Bryan Sanchez\\AppData\\Local\\Temp\\ipykernel_3748\\3626396832.py:104: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_periods['censor_weight'].fillna(1.0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Models Summary:\n",
      "  Censor Weights: 725 rows\n",
      "  Combined Weights: 1780 rows\n",
      "Weight Models Summary:\n",
      "  Switch Weights: 636 rows\n",
      "  Censor Weights: 725 rows\n",
      "  Combined Weights: 1780 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryan Sanchez\\AppData\\Local\\Temp\\ipykernel_3748\\1380208114.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data['const'] = 1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    data_censored = pd.read_csv(\"data/data_censored.csv\")\n",
    "    \n",
    "    # Create trial sequence objects\n",
    "    trial_pp = trial_sequence(estimand=\"PP\")  # Per-protocol\n",
    "    trial_itt = trial_sequence(estimand=\"ITT\")  # Intention-to-treat\n",
    "    \n",
    "    # Create directories\n",
    "    trial_pp_dir = os.path.join(tempfile.gettempdir(), \"trial_pp\")\n",
    "    os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "    \n",
    "    trial_itt_dir = os.path.join(tempfile.gettempdir(), \"trial_itt\")\n",
    "    os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "    \n",
    "    # Set data for both trial sequences\n",
    "    trial_pp = trial_pp.set_data(\n",
    "        data=data_censored,\n",
    "        id=\"id\",\n",
    "        period=\"period\",\n",
    "        treatment=\"treatment\",\n",
    "        outcome=\"outcome\",\n",
    "        eligible=\"eligible\"\n",
    "    )\n",
    "    \n",
    "    trial_itt = trial_itt.set_data(\n",
    "        data=data_censored,\n",
    "        id=\"id\",\n",
    "        period=\"period\",\n",
    "        treatment=\"treatment\",\n",
    "        outcome=\"outcome\",\n",
    "        eligible=\"eligible\"\n",
    "    )\n",
    "    \n",
    "    # Set switch weight models\n",
    "    trial_pp = trial_pp.set_switch_weight_model(\n",
    "        numerator=\"~ age\",\n",
    "        denominator=\"~ age + x1 + x3\",\n",
    "        model_fitter=stats_glm_logit(save_path=os.path.join(trial_pp_dir, \"switch_models\"))\n",
    "    )\n",
    "    \n",
    "    print(trial_pp)\n",
    "    # Set censor weight models\n",
    "    trial_pp = trial_pp.set_censor_weight_model(\n",
    "        censor_event=\"censored\",\n",
    "        numerator=\"~ x2\",\n",
    "        denominator=\"~ x2 + x1\",\n",
    "        pool_models=\"none\",\n",
    "        model_fitter=stats_glm_logit(save_path=os.path.join(trial_pp_dir, \"switch_models\"))\n",
    "    )\n",
    "    \n",
    "    trial_itt = trial_itt.set_censor_weight_model(\n",
    "        censor_event=\"censored\",\n",
    "        numerator=\"~ x2\",\n",
    "        denominator=\"~ x2 + x1\",\n",
    "        pool_models=\"numerator\",\n",
    "        model_fitter=stats_glm_logit(save_path=os.path.join(trial_itt_dir, \"switch_models\"))\n",
    "    )\n",
    "    \n",
    "    # Calculate weights\n",
    "    trial_pp = trial_pp.calculate_weights()\n",
    "    trial_itt = trial_itt.calculate_weights()\n",
    "    \n",
    "    # Show weight models\n",
    "    show_weight_models(trial_itt)\n",
    "    show_weight_models(trial_pp)\n",
    "    \n",
    "    # Set outcome models\n",
    "    trial_pp = trial_pp.set_outcome_model()\n",
    "    trial_itt = trial_itt.set_outcome_model(adjustment_terms=\"~ x2\")\n",
    "    \n",
    "    # Set expansion options\n",
    "    trial_pp = trial_pp.set_expansion_options(\n",
    "        output=save_to_datatable(),\n",
    "        chunk_size=500\n",
    "    )\n",
    "    \n",
    "    trial_itt = trial_itt.set_expansion_options(\n",
    "        output=save_to_datatable(),\n",
    "        chunk_size=500\n",
    "    )\n",
    "    \n",
    "    # Expand trials\n",
    "    trial_pp = trial_pp.expand_trials()\n",
    "    trial_itt = trial_itt.expand_trials()\n",
    "    \n",
    "    # Load expanded data and fit MSM\n",
    "    trial_itt = trial_itt.load_expanded_data(seed=1234, p_control=0.5)\n",
    "    trial_itt = trial_itt.fit_msm(\n",
    "        weight_cols=[\"weight\", \"sample_weight\"],\n",
    "        modify_weights=lambda w: np.minimum(w, np.quantile(w, 0.99))  # Winsorization\n",
    "    )\n",
    "    \n",
    "    # Prepare the prediction data\n",
    "    prediction_data = outcome_data(trial_itt)\n",
    "    prediction_data = prediction_data[prediction_data['trial_period'] == 1]\n",
    "\n",
    "    # Add the 'const' column with value 1\n",
    "    prediction_data['const'] = 1\n",
    "\n",
    "    # Now call predict\n",
    "    preds = trial_itt.predict(\n",
    "        newdata=prediction_data,\n",
    "        predict_times=list(range(11)),  # Assuming you want predictions from 0 to 10\n",
    "        type=\"survival\"\n",
    "    )\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(preds['difference']['followup_time'], preds['difference']['survival_diff'])\n",
    "    plt.plot(preds['difference']['followup_time'], preds['difference']['2.5%'], 'r--')\n",
    "    plt.plot(preds['difference']['followup_time'], preds['difference']['97.5%'], 'r--')\n",
    "    plt.xlabel('Follow up')\n",
    "    plt.ylabel('Survival difference')\n",
    "    plt.title('Treatment Effect on Survival')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('survival_difference.png')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs-3202",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
